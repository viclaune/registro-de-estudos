
1. **Databases gerenciados - Relacional**

Todos os provedores de nuvem trabalham com o conceito de *Database as a Service* (DaaS), ou seja, um serviço de base de dados gerenciado onde o usuário não se preocupa com a instalação, configuração, atualização ou qualquer outra questão de administração da infra sobre a qual a base de dados está implantada. 

Esse modelo PaaS de serviço de nuvem permite que o usuário se concentre na administração dos dados em si e na elaboração da aplicação para geração de valor para o negócio.

- AWS
    - **RDS** (*Relational Database Service*) - Serviço gerenciado (não configuramos nada), somente definimos algumas parâmetros de configuração e consumimos o d*atabase* como um serviço. Compatível com Oracle, Microsoft SQL Server, MySQL, PostgreSQL, MariaDB e Amazon Aurora (banco de dados da amazon, compatível com MySQL e PostgreSQL, e pode ser implantado com a opção *serverless*, podemos utilizar no RDS como um cluster de database *serverless*).
    - Soluções de *Data* *Warehouse*:
        - **Amazon** **Redshift** - Principal ferramenta de DW da Amazon, é um cluster de computação para base de dados robusto.
        - **Amazon** **Redshift** **Spectrum** - Baseado no Redshift mas consegue se comunicar diretamente com arquivos em Data Lake (S3).
- Google Cloud
    - **Solução Bare Metal** - consistem em uma migração *lift-and-shift* para databases Oracle;
    - **Cloud SQL** - Database relacional compatível com MySQL, PostgreSQL e Microsoft SQL Server;
    - **Cloud Spanner** - Serviço compatível com Oracle e com o Amazon Dynamo DB. Apesar de o DynamoDB ser uma solução NoSQL, o Cloud Spanner é o serviço indicado pelo Google para realizar essa migração de provedores.
    - Solução de *Data Warehouse***:**
        - **BigQuery** - Trata-se de uma solução de base dados relacional *serverless* com grande escalabilidade e poder computacional.
    - Os principais serviços de **bancos de dados NoSQL** do Google são:
        - **Cloud** **Bigtable** - chave-valor;
        - **Firestore** - banco de dados de documentos;
        - **Firebase** **Realtime** **Database** - banco de dados de documentos;
        - **Memorystore** - banco de dados em memória compatível com Redis e Memcached;
        - O Google Cloud possui integração com outros bancos de dados através da sua rede de parceiros (MongoDB Atlas, Datastrax, Redis Labs, Neo4j e ElasticSearch)
- Azure
    - Banco de Dados SQL do Azure.
    - Instância Gerenciada de SQL do Azure (SQL Server).
    - SQL Server em Máquinas Virtuais
    - Banco de Dados do Azure para PostgreSQL.
    - Banco de Dados do Azure para MySQL.
    - Banco de Dados do Azure para MariaDB.
    - Soluções de *Data Warehouse*:
        - Azure SQL Data Warehouse
        - Azure Synapse Analytics

1. **Databases gerenciados - Não relacional**
- AWS
    - Chave-valor:
        - DynamoDB - Latência baixíssima, com tabelas replicadas globalmente. Altamente gerenciada (não precisa configurar nada).
    - Documento:
        - DocumentDB (compatível com MongoDB).
    - Grafo:
        - Amazon Neptune
    - Em memória:
        - Amazon Elasticache (Memcached e Redis)
    - Pesquisa:
        - Amazon ElasticSearch Service
- Google
    - Chave-valor:
        - Cloud Bigtable
    - Documento:
        - Firestore;
        - Firebase Realtime Database
    - Em memória:
        - Memorystore (Redis e Memcached)
    - Outros:
        - MongoDB Atlas;
        - MongoDB, Datastax, Redis Labs, Neo4j e ElasticSearch
- Azure
    - Chave-valor:
        - Azure Cosmos DB.
    - Documento:
        - Azure Cosmos DB.
    - Grafo:
        - Azure Cosmos DB.
    - Em memória:
        - Cache do Azure para Redis.
    - Pesquisa:
        - Elastic no Azure

1. **Data Lake - Desenho de Arquitetura**

Neste capítulo, vamos estudar alguns dos principais desenhos de arquitetura conhecidos no mercado, a saber, a arquitetura Lambda, Kappa, Unifield e Data Lakehouse.

**3.1 Arquitetura Lambda**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ec00367b-38e3-4be6-b30e-bcaae539c902/Untitled.png)

Conhecida por possuir duas camadas de processamento em paralelo, uma cada de processamento em lote (*batch layer*) e uma camada de processamento rápido ou quase em tempo real (*speed layer*).

Na imagem, temos no número 1 as fonte de dados que são extraídas tanto para a batch layer, onde vamos ter algum storage de armazenamento dos dados históricos, que vão para a serving layer (camada de serviço para consumo dos dados), vamos utilizar um DW, e no número 5 vamos ter as consultas com ferramentas de BI. 

Na camada rápida (4), normalmente vamos ter algumas ferramenta de *streaming* de dados como Kafka, ou alguma ferramenta cloud como Kinesis (AWS), PubSub (Google). Podemos ter alguma ferramenta de processamento real time como o ksqlDB compatível com Kafka ou o Spark Streaming, e isso vai ser servitor diretamente para o consumo final.

O que define a Arquitetura Lambda é a coexistência da batch layer e da speed layer em paralelo.

**3.2 Arquitetura Kappa**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6ff75d17-6788-499a-9b50-f03a5af2d6ca/Untitled.png)

Temos uma única camada de processamento (*Data Processing Layer*), que vai ser de processamento rápido (*near real time*), para ingestão vamos utilizar Apache Spark, Google Data Flow, Apache Flink… E essa layer de processamento vai servir a camada de *Data Storage* que vai servir como um *Serving Layer*.

Por baixo de tudo que foi falado, vamos ter uma camada de orquestração, monitoramento de logs, eventos e reports.

**3.3 Arquitetura Unifield**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/097aa86a-89c7-48ba-ac3e-ac34c9b87af9/Untitled.png)

- Se parece bastante com a arquitetura Lambda. A principal diferença é que, neste caso, é inserido uma combinação de processamento de dados e *Machine Learning*.
- Modelos de *Machine* *Learning* são treinados e adicionados à *speed layer* para predições em tempo real. Essecialmente a combinação de *data analytics* com *real time machine learning* pode ser bastante frutífera e gerar *insights* potencializados para os usuários, facilitando e empoderando ainda mais a tomada de decisão. Contudo, esta arquitetura possui um maior grau de complexidade em sua implementação.

**3.4 Arquitetura Lakehouse**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/401aae7e-d8b9-4c6f-9357-300fc3b3696a/Untitled.png)

No final da década de 80, as empresas trabalhavam com *Data Warehouses*, tínhamos dados externos e processos de ETL que alimentavam os *Data Marts* (grandes bases relacionais que serviam partes da empresa). Esse modelo evoluiu e em meados de 2011 começamos a trabalhar com *Data* *Lake*.

O *Data Warehouse* e as bases de dados relacionais só permitem trabalhar com dados estruturados, mas com a evolução da internet e das novas tecnologias, surgiram muitos dados semiestruturados e não estruturados, tornando necessário e de grande valor para as empresas o armazenamento destes. Surgiu então o conceito de *Data* *Lakes* que é um storage de objetos que armazena de forma organizada, temos processos de preparação e validação desses dados, entrega para projetos de machine learning. Em paralelo temos também o processo de ETL para criar um *Data Warehouse* mais tradicional. Tornando o Data Lake um repositório centralizador, uma fonte única de "verdade", buscando os dados em sua forma bruta.

Em 2020 temos um novo conceito, o Lakehouse. Tem duas grandes diferenças em relação ao *Data* *Lake*, uma delas é a seguinte: a gente abstrai a camada de *Data Warehouse* (não temos mais *Data Warehouse*, *Data* *Marts*, ou alguma camada estruturada). 

BI’s, *Analytics* em *Streaming*, Cientistas de Dados agora recebem os dados direto do *Data Lake* que possuem *Engines* de *Data* *Lake*, que são Engines de consultas SQL distribuídas, temos no mercado algumas soluções como: Presto, Trino, Dreamium, AWS Athena, etc. Que permitem que executemos consultas de SQL distribuídas diretamente aos arquivos do *Data Lake*, não importa se os dados são CSV, Parquet, JSON, ORC.

Por que o *Data Warehouse* é interessante do ponto de vista transacional? Por que podemos fazer a alteração em uma linha do *database*, quando temos um arquivo, isso se torna custoso, pois precisamos reescrever o arquivo inteiro para alterar uma linha. Em meados de 2020 surgiu o *Delta* *Lake* que nos permite de uma forma simples trabalhar com operações ACID nos arquivos que estão no *Lake*. Conseguimos de forma simples fazer o controle de versão dos dados de forma eficiente e disponibilizar ao usuário final de forma otimizada.

1. **Data Lake - Armazenamento**

Nos provedores de nuvem, é comum utilizarmos soluções de armazenamento de objetos como infraestrutura para construção de Data Lakes.

Na AWS, a principal solução de armazenamento de objetos é o Amazon S3 (*Amazon Simple Storage Service*). Este serviço é praticamente ilimitado quanto ao volume de dados que é possível armazenar. Há um limite de tamanho para objetos únicos de 5 TB.

O S3 é projeto para ofecer uma durabilidade de 11 noves (99,999999999%). Questões internas como replicações e backups.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7d1056d6-2c66-4cc7-afb1-4556a0c7577d/Untitled.png)

Os objetos são colocados nos buckets, e os buckets S3 na AWS vai estar dentro de uma região. Região é o espaço físico onde os recursos da AWS estão alocados, e dentro de cada região existe as zonas de disponibilidade (data center físico), cada região possui pelo menos 3 zonas. Quando colocamos um objeto em uma região, o S3 faz a replicação em todas as zonas de disponibilidade daquela região, o que permite que os dados sejam duráveis e disponíveis.

S3 possui um modelo de custo *pays as you go* ou “pague pelo o que consumir”. O custo é calculado por GBs armazandos por mês e pelo tráfego de dados para fora da AWS ou para outras regiões. É pago também por solicitações PUT, COPY, POST, LIST e GET. 

Não entram no cálculo de custos o tráfego para dentro do S3 e tráfego para fora do S3 quando o destino é o Serviço Amazon Cloud Front (distribuição de conteúdo da AWS) ou instâncias EC2 que estejam na mesma região.

1. **Data Lake - Ingestão de dados**

A ingestão de dados no Data Lake pode acontecer das seguintes formas:

- **Em batch, uma única vez** - Processos únicos de ingestão full de tabelas ou fontes de dados completas;
- **Em batch, por substituição (overwrite) programada** - similar ao caso anterior, porém com repetição periódica e sobrescrita dos dados depositados no lake.
- **Em batch incremental** - ingestão em lotes, porém incremental.
- **Near-real-time incremental** - ingestão por eventos ou micro batches de eventos.

Possíveis fontes de dados que podemos fazer ingestão: tabelas em bases relacionais ou NoSQL, sinais ou objetos vindos de algum sensor, APIs, Arquivos em file system externo.

Para ingestão em bath, podemos utilizar as seguintes ferramentas: Spark, Python, Apache Nifi (nasceu para ser orquestrador, mas consegue se conectar com várias fontes de dados). Para ingestão em near-real-time é o Kafka, que é a principal ferramenta para esse serviço.

Existem alguns serviços gerenciados para fazer ingestão, na AWS temos o DMS que permite fazer a ingestão em batch quanto a ingestão near-real-time pois permite realizar uma técnica chamada CDC (Change Data Capture) que escuta uma base de dados, escuta as transformações, updates e faz a migração para os lakes. E para eventos, temos os serviços Kinesis da AWS, o PubSub do Google e o Azure Event Hub, fazendo coisas similares ao Kafka.

1. **Data Lake - Processamento de Big Data**

Open Source para fazer processamento de Big Data, em batch temos o Apache Spark. Para *real-time* podemos utilizar o Apache Spark, e existem o ksqlDB que roda em cima do Kafka e é específica para processamento de dados *real-time*, diferente do spark que podemos utilizar diferentes linguagens, no ksqlDB utilizamos exclusivamente SQL.

Se tratando de soluções gerenciadas:

- AWS:
    - EMR (*batch* e *real-time*) - Basicamente é um cluster spark na AWS.
    - Glue Job (*batch* e *real-time*) - Basicamente são jobs spark em que podemos fazer batch e real-time. A diferença entre o Glue e o EMR é que o EMR é mais parecido com o RDS (PaaS), enquanto o Glue é um produto *serverless*. é um serviço serverless
    - Kinesis Data Analytics (*real-time*) - Basicamente um ambiente Kafka.
- Azure:
    - HD Insight (*batch* e *real-time*)
    - Azure Stream Analytics (*real-time*)
- Google Cloud:
    - Dataproc - Serviço de cluster spark no Google.
    - PubSub - Implementação do Kafka no Google.
    - BigQuery - Capacidade de processamento gigante, utilizada para processamento em batch.
- Databricks
    - Principais mantenedores do Spark com plataforma própria de Big Data.

1. **Data Lake - Consumo de Dados - Data Warehouse e Engines**

As engines de consultas a Data Lake surgiram como uma alternativa às estruturas de Data Warehouse que não permitiam a melhor otimização de custos nem a fácil integração com dados semiestruturados. Quando gerenciados pelos provedores de nuvem, seu modelo de custo é baseado no volume de dados varridos pela consulta.

- AWS
    - Amazon Athena - Abstrai a existência de um DW. Possui um modelo de custo por requisição, pelo volume de dados que seja varrido pela consulta. É utilizado junto ao Glue Data Catalog, que possui crawlers que entendem os esquemas das tabelas e disponibilizam para o AWS Athena para realizar consultas SQL contra os arquivos que estão no Lake.
- Azure
    - Azure Data Lake Analytics - Similar ao Amazon Athena
- Google Cloud
    - Não possui uma solução de consultas SQL. O serviço mais próximo seria o BigQuery que não se define de tal forma, mas antes como um Data Warehouse serverless.

Existem várias soluções open source para utilização na infraestrutura de nuvem. Trabalhar com as soluções open source exige que o usuário cuide do deploy, monitoramento e manutenção das soluções (modelo IaaS). Contudo, elas são igualmente ou até mais robustas do que as soluções gerenciadas. São elas:

- Presto
- Trino - evolução do Presto SQL
- Apache Drill
- Dremio
