1. Outra forma de trabalhar com cluster Spark na AWS de uma maneira diferente é usando um serviço chamado Glue. O Glue é um cluster Spark totalmente *serverless* (não vê máquina, não vê nada), só vamos criar o Job, criar o código spark, colocar para executar e ele vai fazê-lo. No AWS Glue, vamos na aba de ETL → Jobs.

2. Vamos começar a configurar, existe uma forma visual de definir jobs Spark com o Glue
Studio. Mas vamos nos ater ao código PySpark. Vamos criar um nome <glue_job_nome>, escolher uma IAM role (podemos utilizar a que já foi criada em projetos anteriores), definimos o tipo de Job (Spark). Uma desvantagem do Glue com relação ao EMR é que precisaremos trabalhar com versões menos atualizadas do Spark. This job runs: Podemos gerar um script pelo Glue, podemos prover um caminho para um arquivo existente ou abrir um editor e escrever um script. Vamos selecionar uma pasta para guardar o script no Data Lake (criar uma pastinha chamada glue-script), na qual o script PySpark estará.

3. Em conexões, não faremos conexão com nenhum database, iremos trabalhar apenas com o Data Lake. Vamos salvar o Job e editar o script. Na tela do Data Lake teremos o arquivo Spark e iremos clicar em Edit Script. Temos então um script Spark quase comum, muito parecido com o EMR, mas com algumas diferenças, uma dessas coisas é precisar importar algumas bibliotecas e módulos:

```python
import sys
from pyspark.context import SparkContext
from awsglue.utils import getResolvedOptions
from awsglue.context import GlueContext

from awsglue.job
import Job

## @params: [‘JOB_NAME’]

args = getResolvedOption(sys.argv, [‘JOB_NAME’])
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job.init(args[‘JOB_NAME’, args]

# A partir daqui, exatamento o mesmo codigo executado no EMR.

# ler os dados do enem

enem = (
	spark
	.read
	.format(‘csv’)
	.option(‘header’, True)
	.option(‘inferSchema’, True)
	.option(‘delimiter’, ‘;’ )
	.load(‘<path>’)
)

# Escrever no DataLake em parquet
(
enem
	.write
	.mode(‘overwrite’)
	.format(‘parquet’)
	.partitionBy(‘year’)
	.save(‘<path>/staging/enem-glue’)
)
```

4. Salvo o código Spark, vamos executá-lo. Selecionar o Job e executar. A nossa
expectativa é que ele não rode, por que se olhar os details, a role utilizada para o job não possui permissão específica para completar a execução do job. Para resolver esse problema, devemos ir em policies e adicionar permissoes, em actions. Ou ir no JSON e adicionar as capacidades necessárias.

5. Qual a diferença entre o Glue e o EMR? Temos diferenças na versão do spark e na
escrita do código, no Glue é preciso acrescentar alguns parâmetros específicos (configuração default). O Glue é um serviço serverless (montamos o código e enviamos para ser rodado), a máquina dedicada à servir o Glue possui uma grande capacidade. O Glue por ser serverless é o modelo *pay-as-you-go*, você paga pelo tempo de execução e o EMR se paga pelo tempo de uso.

6. Serviços de IAM, Roles, Policies, Users, é tudo gratuito.