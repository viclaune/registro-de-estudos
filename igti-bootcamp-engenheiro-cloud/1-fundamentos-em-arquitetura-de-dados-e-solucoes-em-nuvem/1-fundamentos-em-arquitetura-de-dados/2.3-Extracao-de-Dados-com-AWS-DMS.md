Nesta prática vamos fazer um exercício com o DMS (*Database Migration Service*), configurar uma instância de replicação no DMS, configurar *endpoints* *source* (fonte) e *target* (destino do DMS) e vamos executar uma *task* de migração.

1. No console da AWS vamos entrar no serviço DMS (serviço para fazer migração de dados). Nesta prática vamos fazer uma migração FULL de uma tabela. O DMS tem algumas partes para configurar, no fim das contas, vamos subir uma instância de configuração que basicamente vai ser uma máquina EC2 (máquina virtual) com o programa do DMS instalado e sendo executado lá dentro, vamos configurar os *endpoints* (onde está a fonte e o destino dos dados) e vamos configurar uma tarefa de migração (*tasks*).
2. (A primeira coisa a fazer é instanciar uma *replication instance*. **Replication instance configuration:** vamos colocar um nome, uma descrição, vamos definir qual instância vamos utilizar, lembre que quanto mais forte a máquina, mais cara ela é. A *engine* deve ser a mais atual, já a VPC devemos escolher a *default* da região. **Advanced** **security** **and** **network** **configuration:** no *availability* *zone* para otimizar os custos devemos colocar o DMS na mesma zona do RDS. No Security group colocamos *default*. **Tags** sempre são importantes tagear para deixar claro o trabalho.
3. Como próximos passos vamos criar os *endpoints*, vamos ter que criar dois *endpoints*: *source* (fonte) e o *target* (destino). Vamos primeiro criar o endpoint, em DMS → Endpoint → Create endpoint: Vamos escolher primeiro se é fonte ou destino, se estiver no RDS é mais fácil, é só selecionar e escolher a RDS; colocamos um nome, escolhemos a Source engine, por default já vem alguns configurações, colocamos nosso username e senha. **Tags**: Vamos tagear. **Test** **endpoint** **connection**: vamos testar a conexão, e se a permissão do RDS em inbound rules não estiver liberada para o acesso pela DMS, vai ser negada a conexão, no inbound devemos então fazer a liberação, e adicionar o default de segurança. Endpoint source criado.
4. Agora criando um *endpoint* *target*. Em **endpoint** **configuration**: Escolhemos para qual serviço da Amazon vamos enviar os dados, vamos usar o S3. Colocamos o nome do bucket e uma pasta para esse bucket. 
5. Teremos que ir no IAM para cuidar da **Role** de acesso. Em IAM → Role, vamos criar uma role para o DMS. Na barra *Search* vamos marcar o **AmazonS3FullAccess**. Definir um nome da role e sua descrição. Nas roles, vamos buscar a permissão dada (que vai aparecer pelo nome definido), copiamos a **Role ARN** e preenchemos em **Service access role ARN** do *endpoint target* do DMS.
6. Por default, quando definimos um target S3, por default, todos os dados vão migrar utilizando o `.csv`. Para otimizar tanto a performance quanto o storage, vamos adicionar alguns parâmetros para passar os dados para parquet. **Settings:** vamos adicionar `DataFormat → Parquet`; `ParquetVersion →PARQUET_2_0` e `ParquetTimeStamplnMillisecond → true`.
7. Agora em **Database migration tasks**. Vamos configurar uma task de migração de dados, em Task identifier passamos o nome da *task*, junto à uma descrição. Passamos a instância de replicação, o endpoint source e o *target*, e o *migration* *type* vamos escolher o *Migrate existing data*. **Task** **settings**: vamos definir alguns parametros da migração, podemos deixar dropar, limited lob mode. Em **Table** **mappings**: Vamos definir o que vai ser migrado, se deixar default ele vai migrar a tabela inteira, vamos definir que vamos migrar apenas o *Schema* *public*, e o nome da tabela em Table name, em action definimos se estamos incluindo ou excluindo algo da nossa tabela, e ainda podemos adicionar filtros avançados, como por exemplo, uma coluna específica; podemos fazer transformações, adicionar coluna… Não vamos fazer o **Premigration** **assessment**. E vamos tagear os recursos.
8. **Database** **migration** **task**: Task realizada, podemos ver no S3 o nosso dado migrado.